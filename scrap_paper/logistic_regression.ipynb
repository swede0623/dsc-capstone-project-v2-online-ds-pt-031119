{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "import pickle \n",
    "#import mglearn\n",
    "import time\n",
    "\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # doesn't split at apostrophes\n",
    "import nltk\n",
    "from nltk import Text\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.tokenize import sent_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "holdout = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_df = pd.read_csv(\"test_labels.csv\")\n",
    "holdout = holdout.merge(test_labels_df, on='id')\n",
    "holdout.drop(holdout[holdout['toxic']==-1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['char_total'] = train['comment_text'].map(lambda x: len(x))\n",
    "# train = train[train['char_total']<2000]\n",
    "# train.drop(['char_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower everything\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: x.lower())\n",
    "\n",
    "# remove '\\\\n'\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
    "    \n",
    "# remove any text starting with User... \n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
    "    \n",
    "# remove IP addresses or user IDs\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
    "    \n",
    "#remove http links in the text\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"(http://.*?\\s)|(http://.*)\",'',str(x)))\n",
    "\n",
    "#remove https links in the text\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"(https://.*?\\s)|(https://.*)\",'',str(x)))\n",
    "\n",
    "#remove email addresses \n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\",'',str(x)))\n",
    "\n",
    "#remove WP:__\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"wp:\\w*\",'',str(x)))\n",
    "\n",
    "#remove user::__\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"user::\\w*\",'',str(x)))\n",
    "\n",
    "#remove all websites\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"^(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?$\",'',str(x)))\n",
    "\n",
    "#remove all these auto-generated messages\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: re.sub(\"preceding unsigned comment added by\",'',str(x)))\n",
    "\n",
    "#remove all punctuation\n",
    "train['comment_text'] = train['comment_text'].map(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower everything\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: x.lower())\n",
    "\n",
    "# remove '\\\\n'\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
    "    \n",
    "# remove any text starting with User... \n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
    "    \n",
    "# remove IP addresses or user IDs\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
    "    \n",
    "#remove http links in the text\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub(\"(http://.*?\\s)|(http://.*)\",'',str(x)))\n",
    "\n",
    "#remove https links in the text\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub(\"(https://.*?\\s)|(https://.*)\",'',str(x)))\n",
    "\n",
    "#remove email addresses \n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub(\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\",'',str(x)))\n",
    "\n",
    "#remove WP:__\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub(\"wp:\\w*\",'',str(x)))\n",
    "\n",
    "#remove user::__\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub(\"user::\\w*\",'',str(x)))\n",
    "\n",
    "#remove all websites\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub(\"^(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?$\",'',str(x)))\n",
    "\n",
    "#remove all these auto-generated messages\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: re.sub(\"preceding unsigned comment added by\",'',str(x)))\n",
    "\n",
    "#remove all punctuation\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_digits(comment):\n",
    "    result = ''.join([i for i in comment if not i.isdigit()])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train['comment_text'].apply(remove_all_digits)\n",
    "holdout['comment_text'] = holdout['comment_text'].apply(remove_all_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sample = train.sample(50000, random_state=0)\n",
    "# test_sample = holdout.sample(25000, random_state=0)\n",
    "X_train = train['comment_text']\n",
    "y_train = train.iloc[:, 2:]\n",
    "X_test = holdout['comment_text']\n",
    "y_test = holdout.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('English') + list(string.punctuation) + [\"''\", '\"\"', '...', '``']\n",
    "stopwords_list += ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october',\n",
    "                  'november', 'december']\n",
    "stopwords_list += ['jan', 'feb', 'mar', 'apr', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec', 'utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the vectorizer\n",
    "word_vectorizer = TfidfVectorizer(stop_words='english', token_pattern=r'\\w{2,}')\n",
    "\n",
    "# fit and transform on it the training features\n",
    "word_vectorizer.fit(X_train)\n",
    "X_train_word_features = word_vectorizer.transform(X_train)\n",
    "\n",
    "#transform the test features to sparse matrix\n",
    "test_features = word_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Log_loss score for class toxic is -0.12582401755143963\n",
      "CV Accuracy score for class toxic is 0.9540079334117537\n",
      "CV ROC_AUC score 0.9582069370012736\n",
      "\n",
      "CV Log_loss score for class severe_toxic is -0.029413328820513895\n",
      "CV Accuracy score for class severe_toxic is 0.9904493942384776\n",
      "CV ROC_AUC score 0.9825804509930656\n",
      "\n",
      "CV Log_loss score for class obscene is -0.06909915233536419\n",
      "CV Accuracy score for class obscene is 0.976280154686046\n",
      "CV ROC_AUC score 0.9728234874997391\n",
      "\n",
      "CV Log_loss score for class threat is -0.012163961316997022\n",
      "CV Accuracy score for class threat is 0.9971298053476418\n",
      "CV ROC_AUC score 0.9840944933037836\n",
      "\n",
      "CV Log_loss score for class insult is -0.0853174051844743\n",
      "CV Accuracy score for class insult is 0.9690921387889831\n",
      "CV ROC_AUC score 0.9655307171192983\n",
      "\n",
      "CV Log_loss score for class identity_hate is -0.0288908321732697\n",
      "CV Accuracy score for class identity_hate is 0.9917967558729014\n",
      "CV ROC_AUC score 0.9770736260881024\n",
      "\n",
      "Total average CV Log_loss score is -0.058451449563676455\n",
      "Total average CV ROC_AUC score is 0.973384952000877\n"
     ]
    }
   ],
   "source": [
    "class_names = ['toxic','severe_toxic','obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "losses = []\n",
    "auc = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    #call the labels one column at a time so we can run the classifier on them\n",
    "    train_target = y_train[class_name]\n",
    "    test_target = y_test[class_name]\n",
    "    classifier = LogisticRegression(solver='liblinear')\n",
    "\n",
    "    cv_loss = np.mean(cross_val_score(classifier, X_train_word_features, train_target, cv=5, scoring='neg_log_loss'))\n",
    "    losses.append(cv_loss)\n",
    "    print('CV Log_loss score for class {} is {}'.format(class_name, cv_loss))\n",
    "    \n",
    "    cv_score = np.mean(cross_val_score(classifier, X_train_word_features, train_target, cv=5, scoring='accuracy'))\n",
    "    print('CV Accuracy score for class {} is {}'.format(class_name, cv_score))\n",
    "    \n",
    "    classifier.fit(X_train_word_features, train_target)\n",
    "    y_pred = classifier.predict(test_features)\n",
    "    y_pred_prob = classifier.predict_proba(test_features)[:, 1]\n",
    "    auc_score = metrics.roc_auc_score(test_target, y_pred_prob)\n",
    "    auc.append(auc_score)\n",
    "    print(\"CV ROC_AUC score {}\\n\".format(auc_score))\n",
    "    \n",
    "print('Total average CV Log_loss score is {}'.format(np.mean(losses)))\n",
    "print('Total average CV ROC_AUC score is {}'.format(np.mean(auc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
