{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eric Sundstrom\n",
    "- Data Science Online Program\n",
    "- Part-Time Cohort 3/19\n",
    "- Instructor - Victor Geislinger\n",
    "- Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my Capstone Project, I decided to tackle the (already completed) Kaggle Competition: Toxic Comment Classification Challenge by Jigsaw and Conversation AI\n",
    "\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
    "\n",
    "Going through the curriculum, NLP Natural Language Processing stood out to me.  There seemed to be so many options one could take to improve your model, from pre-processing, tokenization, to the modeling itself.  So I thought completing this task would be a great chance to dive deeper into the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About The Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The goal of this task was to create a model to analyze comments from past Wikipedia edit pages and classify them for 6 different types of toxicity:\n",
    "\n",
    "- toxic\n",
    "- severe toxic\n",
    "- obscene\n",
    "- threat\n",
    "- insult\n",
    "- identity hate\n",
    "\n",
    "- This is a multi-label classification task.  Each label, itself, is a binary classification task\n",
    "\n",
    "- These comments were gathered from Wikipedia, from the time period of 2004 to 2015.  The comments were hand-labeled by real people via crowdsourcing.\n",
    "\n",
    "- The ultimate goal being, for Wikipedia and other places where there is online communication, finding more accurate ways to automatically remove comments that contain toxicity.  Toxicity is harmful to people and stunts productive communication.\n",
    "\n",
    "- I think the point of not just classifying toxic vs non-toxic, but incorporating these sub groups of toxicity is because some online forums are okay with obscenities but not if used in making threats or insults, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      "id               159571 non-null object\n",
      "comment_text     159571 non-null object\n",
      "toxic            159571 non-null int64\n",
      "severe_toxic     159571 non-null int64\n",
      "obscene          159571 non-null int64\n",
      "threat           159571 non-null int64\n",
      "insult           159571 non-null int64\n",
      "identity_hate    159571 non-null int64\n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see the train dataset has about 160,000 comments in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153164 entries, 0 to 153163\n",
      "Data columns (total 2 columns):\n",
      "id              153164 non-null object\n",
      "comment_text    153164 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "holdout = pd.read_csv('test.csv')\n",
    "holdout.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The test data set appears to have about 150,000 comments.  But it was later revealed that many of these were not actually used to evaluate competitor's models, they were just decoys.\n",
    "\n",
    "- The decoys were obvious because their labels were all -1, instead of a valid 0 or 1 value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Test Comments & Labels\n",
    "\n",
    "- By merging dataframes of the test comments and test labels we can easily filter out the decoys so we only use the comments actually used in evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 63978 entries, 5 to 153156\n",
      "Data columns (total 8 columns):\n",
      "id               63978 non-null object\n",
      "comment_text     63978 non-null object\n",
      "toxic            63978 non-null int64\n",
      "severe_toxic     63978 non-null int64\n",
      "obscene          63978 non-null int64\n",
      "threat           63978 non-null int64\n",
      "insult           63978 non-null int64\n",
      "identity_hate    63978 non-null int64\n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_labels_df = pd.read_csv(\"test_labels.csv\")\n",
    "holdout = holdout.merge(test_labels_df, on='id')\n",
    "holdout.drop(holdout[holdout['toxic']==-1].index, inplace=True)\n",
    "holdout.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So we see now that our test set really only contains 63,978 comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a breakdown of each label to better understand what type of comments we have been provided in our train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is a look again at our class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(train.columns[2:])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[labels].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So we can see here that the generic toxic class is by far the most plentiful.  While the threat class is the least represented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Labels for each comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because each comment can be marked positive for 6 different labels, another good way to look at our data is to see how many labels each comment was classified positively for in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's create a temporary column for total labels applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  total  \n",
       "0             0        0       0       0              0      0  \n",
       "1             0        0       0       0              0      0  \n",
       "2             0        0       0       0              0      0  \n",
       "3             0        0       0       0              0      0  \n",
       "4             0        0       0       0              0      0  \n",
       "5             0        0       0       0              0      0  \n",
       "6             1        1       0       1              0      4  \n",
       "7             0        0       0       0              0      0  \n",
       "8             0        0       0       0              0      0  \n",
       "9             0        0       0       0              0      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['total'] = train[labels].sum(axis=1)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1      6360\n",
       "3      4209\n",
       "2      3480\n",
       "4      1760\n",
       "5       385\n",
       "6        31\n",
       "Name: total, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['total'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This makes it easy to see that 143346 (89.8% of the total) comments were not labeled for any type of toxicity, so by default they are non-toxic.\n",
    "\n",
    "- Notably, only 6 comments were labeled positively for ALL types of toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a clear contrast for the type of comments in our dataset, let's observe a non-toxic comment and one of the 31 comments that was labeled for all types of toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Minor Counties \\n\\nReference should be made to the work on the Minor Counties. A very solid piece of primary research over many years.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(list(train.loc[train['total']==0, 'comment_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Go fuck yourself!!! you fucking delteted it anyway! whats the fucking point of a public Encyclopedia if you delete evrything!?!?!? I've edited a few pages so that they are more dettailed and wtf do you all do!?!!?!?!?!?! fucking get rid of it!!!!!!! and dumb down articles just to cater for you publicly ignorant american twats I hope George Bush gets killed by Islams fuck you all!!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(list(train.loc[train['total']==6, 'comment_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This makes it easy to see why we to need control toxic communication on the internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Character Limit per Comment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long are these comments, usually? Is there a max limit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e33905d438>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comment_char_length = [len(x) for x in train['comment_text']]\n",
    "pd.Series(comment_char_length).hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159571.000000\n",
       "mean        394.073221\n",
       "std         590.720282\n",
       "min           6.000000\n",
       "25%          96.000000\n",
       "50%         205.000000\n",
       "75%         435.000000\n",
       "max        5000.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(comment_char_length).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that there is a maximum character limit for this dataset, 5000.  But the average character length is 394"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the most common words in the corpus (all comments combined together) of toxic comments vs. non-toxic comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 Corpus, 1 for Non-Toxic 1 for Toxic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this easier to process, let's combine all the toxicity classes together for a general toxic corpus, and then a non-toxic corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_comments_df = train[train['total']== 0]\n",
    "toxic_comments_df = train[train['total'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Each Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NLTK's FreqDist function expects the text to already be in tokenized form, so we will have to do that first.  As it is now, each comment is just a single string of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "from nltk import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I like to use NLTK's TweetTokenizer to turn these comments into word tokens.  It does not split words on their apostrophes, which I like because you don't end up with fragments of what the intended word was supposed to be (for example the word \"they're\" stays that way instead of being split into \"they\" and \"re\")\n",
    "\n",
    "- It also has reduce_len parameter that replaces repeated character sequences of 3 or more with just the sequence of 3\n",
    "\n",
    "- The preserve_case parameters will be set to False because we want the text in lower-case form\n",
    "\n",
    "- Basically, this function is better able to handle informal text conversation like we see with our Wikipedia edit comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_tknzr = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "clean_tokens = [twt_tknzr.tokenize(x) for x in clean_comments_df['comment_text']]\n",
    "toxic_tokens = [twt_tknzr.tokenize(x) for x in toxic_comments_df['comment_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Sample of Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from an example of a comment now in tokenized form, stop words and punctuation are still included.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation',\n",
       " 'why',\n",
       " 'the',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'under',\n",
       " 'my',\n",
       " 'username',\n",
       " 'hardcore',\n",
       " 'metallica',\n",
       " 'fan',\n",
       " 'were',\n",
       " 'reverted',\n",
       " '?',\n",
       " 'they',\n",
       " \"weren't\",\n",
       " 'vandalisms',\n",
       " ',',\n",
       " 'just',\n",
       " 'closure',\n",
       " 'on',\n",
       " 'some',\n",
       " 'gas',\n",
       " 'after',\n",
       " 'i',\n",
       " 'voted',\n",
       " 'at',\n",
       " 'new',\n",
       " 'york',\n",
       " 'dolls',\n",
       " 'fac',\n",
       " '.',\n",
       " 'and',\n",
       " 'please',\n",
       " \"don't\",\n",
       " 'remove',\n",
       " 'the',\n",
       " 'template',\n",
       " 'from',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'since',\n",
       " \"i'm\",\n",
       " 'retired',\n",
       " 'now',\n",
       " '.',\n",
       " '89.205',\n",
       " '.',\n",
       " '38.27']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can now remove those to more clearly see what words best characterize toxic comments and non-toxic comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words and Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('English') + list(string.punctuation)\n",
    "\n",
    "clean_tokens_stops_removed = []\n",
    "for token_list in clean_tokens:\n",
    "    new_tokens = [token for token in token_list if token not in stopwords]\n",
    "    clean_tokens_stops_removed.append(new_tokens)\n",
    "    \n",
    "toxic_tokens_stops_removed = []\n",
    "for token_list in toxic_tokens:\n",
    "    new_tokens = [token for token in token_list if token not in stopwords]\n",
    "    toxic_tokens_stops_removed.append(new_tokens)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-inspect Sample Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'username',\n",
       " 'hardcore',\n",
       " 'metallica',\n",
       " 'fan',\n",
       " 'reverted',\n",
       " 'vandalisms',\n",
       " 'closure',\n",
       " 'gas',\n",
       " 'voted',\n",
       " 'new',\n",
       " 'york',\n",
       " 'dolls',\n",
       " 'fac',\n",
       " 'please',\n",
       " 'remove',\n",
       " 'template',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'since',\n",
       " \"i'm\",\n",
       " 'retired',\n",
       " '89.205',\n",
       " '38.27']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens_stops_removed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, numbers are still included in these tokens, but we will leave it as it is for now and revisit doing more pre-processing before we do our modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Nested List of Tokens for FreqDist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FreqDist wants 1 big list of tokens and not a list of each comment's list of tokens so we have to flatten the nested list before executing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_together_clean = []\n",
    "for comment in clean_tokens_stops_removed:\n",
    "    all_comments_together_clean += comment\n",
    "    \n",
    "all_comments_together_toxic = []\n",
    "for comment in toxic_tokens_stops_removed:\n",
    "    all_comments_together_toxic += comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Frequency Distribution for Clean Corpus & Inspect 20 Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('article', 54154),\n",
       " ('page', 43505),\n",
       " ('wikipedia', 39511),\n",
       " ('talk', 35219),\n",
       " ('please', 28654),\n",
       " ('would', 28085),\n",
       " ('one', 26513),\n",
       " ('like', 23987),\n",
       " ('see', 20525),\n",
       " ('also', 19774),\n",
       " ('think', 18670),\n",
       " ('edit', 16718),\n",
       " ('know', 16688),\n",
       " ('...', 16556),\n",
       " (\"i'm\", 16232),\n",
       " ('articles', 15994),\n",
       " ('use', 15859),\n",
       " ('people', 15809),\n",
       " ('may', 15245),\n",
       " ('time', 14330)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frq_dist_clean = FreqDist(all_comments_together_clean)\n",
    "frq_dist_clean.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Frequency Distribution for Toxic Corpus & Inspect 20 Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fuck', 9623),\n",
       " ('like', 3781),\n",
       " ('shit', 3660),\n",
       " ('wikipedia', 3553),\n",
       " ('nigger', 3294),\n",
       " ('suck', 3245),\n",
       " ('fucking', 3238),\n",
       " ('go', 2963),\n",
       " ('ass', 2954),\n",
       " ('...', 2904),\n",
       " ('u', 2903),\n",
       " ('hate', 2637),\n",
       " ('get', 2440),\n",
       " ('page', 2356),\n",
       " ('know', 2354),\n",
       " ('gay', 2255),\n",
       " ('die', 2141),\n",
       " ('faggot', 2026),\n",
       " ('people', 1994),\n",
       " ('fat', 1981)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frq_dist_toxic = FreqDist(all_comments_together_toxic)\n",
    "frq_dist_toxic.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0 of the top 20 words in non-toxic comments are vulgar or meant to be derogatory vs. 11 of the top 20 words in toxic comments\n",
    "\n",
    "- The difference between the words used in each of these corpus' is stark, as you would probably expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A more sophisticated way to characterize the most important words in a corpus, as opposed to another, is using TF-IDF (Term Frequency- Inverse Document Frequency).  \n",
    "\n",
    "- This method highlights words that are exclusive to a corpus, rather than being common in both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join List of Tokens to One Big String for each Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unlike FreqDist, TfidfVectorizer takes in a string rather than a list of tokens so we'll need to join all our tokens together as one big string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_string_tfidf = ' '.join(all_comments_together_clean)\n",
    "toxic_string_tfidf = ' '.join(all_comments_together_toxic)\n",
    "corpi = [clean_string_tfidf, toxic_string_tfidf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Corpi into Vectors using TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "corpi_tfidf = vectorizer.fit_transform(corpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, each text corpus has been transformed into a vector of TF_IDF scores.  \n",
    "- Basically, the higher the score, the more important it is deemed to be in describing the nature of the document.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Top 20 TFIDF Scores from Clean Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>0.348036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikipedia</th>\n",
       "      <td>0.276245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <td>0.273354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk</th>\n",
       "      <td>0.221235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>please</th>\n",
       "      <td>0.178194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.174744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.170518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.150177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.127589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>0.122916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0.115960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edit</th>\n",
       "      <td>0.106925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>0.104089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>0.101588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>articles</th>\n",
       "      <td>0.100254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>0.099795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>0.094719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.091225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanks</th>\n",
       "      <td>0.083562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <td>0.078709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tfidf\n",
       "article    0.348036\n",
       "wikipedia  0.276245\n",
       "page       0.273354\n",
       "talk       0.221235\n",
       "please     0.178194\n",
       "would      0.174744\n",
       "one        0.170518\n",
       "like       0.150177\n",
       "see        0.127589\n",
       "also       0.122916\n",
       "think      0.115960\n",
       "edit       0.106925\n",
       "know       0.104089\n",
       "people     0.101588\n",
       "articles   0.100254\n",
       "use        0.099795\n",
       "may        0.094719\n",
       "time       0.091225\n",
       "thanks     0.083562\n",
       "user       0.078709"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus = corpi_tfidf[0]\n",
    "df = pd.DataFrame(clean_corpus.T.todense(), index=vectorizer.get_feature_names(), columns=['tfidf'])\n",
    "df = df[df['tfidf']>0]\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Top 20 TFIDF Scores from Toxic Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>0.508336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikipedia</th>\n",
       "      <td>0.199827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.193523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shit</th>\n",
       "      <td>0.187830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fucking</th>\n",
       "      <td>0.169632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nigger</th>\n",
       "      <td>0.168056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suck</th>\n",
       "      <td>0.165158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ass</th>\n",
       "      <td>0.152653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0.150671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>0.135014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>0.124339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <td>0.120831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>0.120476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gay</th>\n",
       "      <td>0.115240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die</th>\n",
       "      <td>0.108835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>0.105124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faggot</th>\n",
       "      <td>0.103090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat</th>\n",
       "      <td>0.100752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moron</th>\n",
       "      <td>0.095872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitch</th>\n",
       "      <td>0.093585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tfidf\n",
       "fuck       0.508336\n",
       "wikipedia  0.199827\n",
       "like       0.193523\n",
       "shit       0.187830\n",
       "fucking    0.169632\n",
       "nigger     0.168056\n",
       "suck       0.165158\n",
       "ass        0.152653\n",
       "go         0.150671\n",
       "hate       0.135014\n",
       "get        0.124339\n",
       "page       0.120831\n",
       "know       0.120476\n",
       "gay        0.115240\n",
       "die        0.108835\n",
       "people     0.105124\n",
       "faggot     0.103090\n",
       "fat        0.100752\n",
       "moron      0.095872\n",
       "bitch      0.093585"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_corpus = corpi_tfidf[1]\n",
    "df = pd.DataFrame(toxic_corpus.T.todense(), index=vectorizer.get_feature_names(), columns=['tfidf'])\n",
    "df = df[df['tfidf']>0]\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Surprisingly, words like Wikipedia and \"page\" have high scores for both corpi.  \n",
    "\n",
    "- But overall the results are very similar to the most common words in the Frequency Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bigrams instead of Unigrams for our Tfidf Vectors & Inspect top 20 for Each Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will give us an idea of the most common pairs of words rather than just any word by itself.  This can give more insight into the meaning of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "corpi_tfidf = vectorizer.fit_transform(corpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>talk page</th>\n",
       "      <td>0.522786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speedy deletion</th>\n",
       "      <td>0.180529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would like</th>\n",
       "      <td>0.144818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair use</th>\n",
       "      <td>0.129308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http www</th>\n",
       "      <td>0.127827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel free</th>\n",
       "      <td>0.094996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blocked editing</th>\n",
       "      <td>0.094831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk contribs</th>\n",
       "      <td>0.090923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk pages</th>\n",
       "      <td>0.086233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>please stop</th>\n",
       "      <td>0.085862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>criteria speedy</th>\n",
       "      <td>0.083843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikipedia org</th>\n",
       "      <td>0.077634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reliable sources</th>\n",
       "      <td>0.077182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en wikipedia</th>\n",
       "      <td>0.075166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welcome wikipedia</th>\n",
       "      <td>0.072779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>please see</th>\n",
       "      <td>0.069653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article talk</th>\n",
       "      <td>0.066608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>take look</th>\n",
       "      <td>0.065580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let know</th>\n",
       "      <td>0.063564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http en</th>\n",
       "      <td>0.060766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      tfidf\n",
       "talk page          0.522786\n",
       "speedy deletion    0.180529\n",
       "would like         0.144818\n",
       "fair use           0.129308\n",
       "http www           0.127827\n",
       "feel free          0.094996\n",
       "blocked editing    0.094831\n",
       "talk contribs      0.090923\n",
       "talk pages         0.086233\n",
       "please stop        0.085862\n",
       "criteria speedy    0.083843\n",
       "wikipedia org      0.077634\n",
       "reliable sources   0.077182\n",
       "en wikipedia       0.075166\n",
       "welcome wikipedia  0.072779\n",
       "please see         0.069653\n",
       "article talk       0.066608\n",
       "take look          0.065580\n",
       "let know           0.063564\n",
       "http en            0.060766"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus = corpi_tfidf[0]\n",
    "df = pd.DataFrame(clean_corpus.T.todense(), index=vectorizer.get_feature_names(), columns=['tfidf'])\n",
    "df = df[df['tfidf']>0]\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This highlights the importance of pre-processing of text data for NLP projects.  http & www, wikipedia & org, en & wikipedia are all just parts of URLs that were split on the period (.) during tokenization.  Many would argue that URLs are not helpful in identifying document purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fuck fuck</th>\n",
       "      <td>0.319054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moron hi</th>\n",
       "      <td>0.218683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi moron</th>\n",
       "      <td>0.218238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nigger nigger</th>\n",
       "      <td>0.212558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jew fat</th>\n",
       "      <td>0.182952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat jew</th>\n",
       "      <td>0.181766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shit shit</th>\n",
       "      <td>0.170498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suck suck</th>\n",
       "      <td>0.168571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ass ass</th>\n",
       "      <td>0.167088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate hate</th>\n",
       "      <td>0.165616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bark bark</th>\n",
       "      <td>0.148111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wanker wanker</th>\n",
       "      <td>0.142774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pig pig</th>\n",
       "      <td>0.131860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balls balls</th>\n",
       "      <td>0.123500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bullshit bullshit</th>\n",
       "      <td>0.123500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go fuck</th>\n",
       "      <td>0.121311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nipple nipple</th>\n",
       "      <td>0.113122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faggot faggot</th>\n",
       "      <td>0.111936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickhead dickhead</th>\n",
       "      <td>0.092662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die fag</th>\n",
       "      <td>0.092662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      tfidf\n",
       "fuck fuck          0.319054\n",
       "moron hi           0.218683\n",
       "hi moron           0.218238\n",
       "nigger nigger      0.212558\n",
       "jew fat            0.182952\n",
       "fat jew            0.181766\n",
       "shit shit          0.170498\n",
       "suck suck          0.168571\n",
       "ass ass            0.167088\n",
       "hate hate          0.165616\n",
       "bark bark          0.148111\n",
       "wanker wanker      0.142774\n",
       "pig pig            0.131860\n",
       "balls balls        0.123500\n",
       "bullshit bullshit  0.123500\n",
       "go fuck            0.121311\n",
       "nipple nipple      0.113122\n",
       "faggot faggot      0.111936\n",
       "dickhead dickhead  0.092662\n",
       "die fag            0.092662"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_corpus = corpi_tfidf[1]\n",
    "df = pd.DataFrame(toxic_corpus.T.todense(), index=vectorizer.get_feature_names(), columns=['tfidf'])\n",
    "df = df[df['tfidf']>0]\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do our Comments contain lots of spamming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The fact that almost all of these bigrams are the same word twice leads me to believe these existed in comments where someone just spammed the same foul words over and over again, with no real meaning.  Because even if someone was cussing at somebody, rarely does a direct attack include the same word repeated back-to-back\n",
    "\n",
    "- So I think it's possible these bigram results are not representative of the comments as a whole, but skewed by a few long spam messages of cuss words repeated over and over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect 20 Longest Comments in Dataset for Spamming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick look to see if this theory may be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>total</th>\n",
       "      <th>char_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46583</th>\n",
       "      <td>7c7a4bf4c84fe002</td>\n",
       "      <td>hahahahahahahahahahahahahahahahahaha vandalism...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47715</th>\n",
       "      <td>7f79fd5eacbe804c</td>\n",
       "      <td>Block Block Block Block Block Block Block Bloc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74753</th>\n",
       "      <td>c7f72686bf613e4e</td>\n",
       "      <td>Dont Change It!!!! zzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42061</th>\n",
       "      <td>70368dd072aebb42</td>\n",
       "      <td>WANKER WANKER WANKER WANKER WANKER WANKER WANK...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72192</th>\n",
       "      <td>c14532e93d456260</td>\n",
       "      <td>China smells like fart. China smells like fart...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75165</th>\n",
       "      <td>c91d629c6599bb23</td>\n",
       "      <td>IN THE NAME OF YTMND!IN THE NAME OF YTMND!IN T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56834</th>\n",
       "      <td>97e695cfd71944ed</td>\n",
       "      <td>i CAN STILL POST WITH THIS COMPUTER...I SAID B...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46197</th>\n",
       "      <td>7b6b88051eb69303</td>\n",
       "      <td>heil hitler! heil hitler! heil hitler! heil hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131729</th>\n",
       "      <td>c0e076f0011acaa6</td>\n",
       "      <td>\"FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128782</th>\n",
       "      <td>b0b8f1eaa83616fe</td>\n",
       "      <td>sex fucksex fucksex fucksex fucksex fucksex fu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121718</th>\n",
       "      <td>8b31f2d7d6025482</td>\n",
       "      <td>BUTTSECKS BUTTSECKS BUTTSECKS BUTTSECKS BUTTSE...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133254</th>\n",
       "      <td>c8f01ac90c4adc27</td>\n",
       "      <td>FUCK YOU ALL!!  FUCK YOU ALL!!  FUCK YOU ALL!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35316</th>\n",
       "      <td>5e50cf56f160bda3</td>\n",
       "      <td>MarxismLONG LIVE ANONYMOUS PHILIPPINESLONG LIV...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82636</th>\n",
       "      <td>dd0bd64b02c550af</td>\n",
       "      <td>MUAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHA, YOU C...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>300b0c81ea94e02d</td>\n",
       "      <td>Hey guys I love chicken rice=)Hey guys I love ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0b2055f13934a41e</td>\n",
       "      <td>ii CAN STILL POST WITH THIS COMPUTER...I SAID ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96267</th>\n",
       "      <td>02dd3c9a9129c83e</td>\n",
       "      <td>BOOTSTOOTS IS A FRIGGEN GAYFAG LOLOOOLBOOTSTOO...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28855</th>\n",
       "      <td>4c7963eaf9697d35</td>\n",
       "      <td>JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70544</th>\n",
       "      <td>bcc6a4fc5f123163</td>\n",
       "      <td>delete this pagedelete this pagedelete this pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63392</th>\n",
       "      <td>a99aff4a8428dfb2</td>\n",
       "      <td>leari CAN STILL POST WITH THIS COMPUTER...I SA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "46583   7c7a4bf4c84fe002  hahahahahahahahahahahahahahahahahaha vandalism...   \n",
       "47715   7f79fd5eacbe804c  Block Block Block Block Block Block Block Bloc...   \n",
       "74753   c7f72686bf613e4e  Dont Change It!!!! zzzzzzzzzzzzzzzzzzzzzzzzzzz...   \n",
       "42061   70368dd072aebb42  WANKER WANKER WANKER WANKER WANKER WANKER WANK...   \n",
       "72192   c14532e93d456260  China smells like fart. China smells like fart...   \n",
       "75165   c91d629c6599bb23  IN THE NAME OF YTMND!IN THE NAME OF YTMND!IN T...   \n",
       "56834   97e695cfd71944ed  i CAN STILL POST WITH THIS COMPUTER...I SAID B...   \n",
       "46197   7b6b88051eb69303  heil hitler! heil hitler! heil hitler! heil hi...   \n",
       "131729  c0e076f0011acaa6  \"FFFFF UUUUUU CCCCCC KKKKKK ===== YOU! F UU C ...   \n",
       "128782  b0b8f1eaa83616fe  sex fucksex fucksex fucksex fucksex fucksex fu...   \n",
       "121718  8b31f2d7d6025482  BUTTSECKS BUTTSECKS BUTTSECKS BUTTSECKS BUTTSE...   \n",
       "133254  c8f01ac90c4adc27  FUCK YOU ALL!!  FUCK YOU ALL!!  FUCK YOU ALL!!...   \n",
       "35316   5e50cf56f160bda3  MarxismLONG LIVE ANONYMOUS PHILIPPINESLONG LIV...   \n",
       "82636   dd0bd64b02c550af  MUAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHA, YOU C...   \n",
       "18183   300b0c81ea94e02d  Hey guys I love chicken rice=)Hey guys I love ...   \n",
       "4174    0b2055f13934a41e  ii CAN STILL POST WITH THIS COMPUTER...I SAID ...   \n",
       "96267   02dd3c9a9129c83e  BOOTSTOOTS IS A FRIGGEN GAYFAG LOLOOOLBOOTSTOO...   \n",
       "28855   4c7963eaf9697d35  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST...   \n",
       "70544   bcc6a4fc5f123163  delete this pagedelete this pagedelete this pa...   \n",
       "63392   a99aff4a8428dfb2  leari CAN STILL POST WITH THIS COMPUTER...I SA...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  total  \\\n",
       "46583       1             0        0       0       0              0      1   \n",
       "47715       0             0        0       0       0              0      0   \n",
       "74753       0             0        0       0       0              0      0   \n",
       "42061       1             0        0       0       0              0      1   \n",
       "72192       1             0        0       0       0              0      1   \n",
       "75165       0             0        0       0       0              0      0   \n",
       "56834       1             1        1       0       1              0      4   \n",
       "46197       1             0        0       0       0              0      1   \n",
       "131729      1             1        1       0       1              0      4   \n",
       "128782      1             1        1       0       0              0      3   \n",
       "121718      1             0        1       0       0              0      2   \n",
       "133254      1             1        1       0       1              0      4   \n",
       "35316       0             0        0       0       0              0      0   \n",
       "82636       1             0        0       0       0              0      1   \n",
       "18183       0             0        0       0       0              0      0   \n",
       "4174        1             0        1       0       1              0      3   \n",
       "96267       1             0        0       0       1              0      2   \n",
       "28855       1             1        0       1       0              0      3   \n",
       "70544       0             0        0       0       0              0      0   \n",
       "63392       1             1        1       0       1              0      4   \n",
       "\n",
       "        char_total  \n",
       "46583         5000  \n",
       "47715         5000  \n",
       "74753         5000  \n",
       "42061         5000  \n",
       "72192         5000  \n",
       "75165         5000  \n",
       "56834         5000  \n",
       "46197         5000  \n",
       "131729        5000  \n",
       "128782        5000  \n",
       "121718        5000  \n",
       "133254        5000  \n",
       "35316         5000  \n",
       "82636         5000  \n",
       "18183         5000  \n",
       "4174          5000  \n",
       "96267         5000  \n",
       "28855         5000  \n",
       "70544         5000  \n",
       "63392         5000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['char_total'] = [len(x) for x in train['comment_text']]\n",
    "train.sort_values(by=['char_total'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wow, it is amazing to see, just from the looking at the top 20 comments in total length, how many of the comments are clearly just spamming words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Modeling\n",
    "\n",
    "- Lots of steps have to be taken so that a machine learning model can process these comments for analysis. There are all sorts of different ways this can done so this is just the direction I went:\n",
    "\n",
    "- Pre-processing\n",
    "- Tokenization\n",
    "- Stemming\n",
    "\n",
    "- Preprocessing is always important to try in NLP, both for possible improvement to the eventual model and for reducing the size of the data/increasing runtimes for subsequent operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unfortunately, many things other than the words people use to actually communicate with each other, can be found in our text data.  \n",
    "\n",
    "- These things include:\n",
    "    - new-line symbols \n",
    "    - IP addresses\n",
    "    - usernames\n",
    "    - website addresses \n",
    "    - auto-generated strings.  \n",
    "    \n",
    "- These types of things don't contain information on toxicity.  We know from common sense, that is not how toxicity or non-toxicity is communicated by humans, even in text form.\n",
    "\n",
    "- Even though something like IP addresses and usernames, which might give clues to the users who tend to be toxic or not, might seem helpful, I think it's better to do without them because ultimately the goal is to predict on unseen data which probably will not have these same usernames and IP addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function for all string manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I made this function to remove these things from a comment, all at one time (I used regular expressions (via the re library) to locate the text I wanted removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(comment):\n",
    "    # lower everything\n",
    "    comment = comment.lower()\n",
    "    #get rid of new line symbols\n",
    "    comment = re.sub('\\\\n',' ',comment)\n",
    "    #remove user:: fragments\n",
    "    comment = re.sub(\"user::\\w*\",' ',comment)\n",
    "    #remove anything with user\n",
    "    comment = re.sub(\"\\[\\[user.*\",' ',comment)\n",
    "    #remove IP addresses\n",
    "    comment = re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",' ',comment)\n",
    "    #remove http links\n",
    "    comment = re.sub(\"(http://.*?\\s)|(http://.*)\",' ',comment)\n",
    "    #remove https links\n",
    "    comment = re.sub(\"(https://.*?\\s)|(https://.*)\",' ',comment)\n",
    "    #remove email addresses\n",
    "    comment = re.sub(\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\",' ',comment)\n",
    "    #remove wp: fragments\n",
    "    comment = re.sub(\"wp:\\w*\",' ',comment)\n",
    "    #remove these auto generated strings\n",
    "    comment = re.sub(\"preceding unsigned comment added by\",' ',comment)\n",
    "    #remove all punctuation besides '\n",
    "    string_w_o_comma = re.sub(\"'\", '', string.punctuation)\n",
    "    comment = comment.translate(str.maketrans('','', string_w_o_comma))\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Copy of Comments for Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before I make changes to our dataset, I want to create a copy of the original, so that I can show that these changes are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Preprocess function to entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our preprocess() function only alters 1 comment at a time, so now we need to use the apply function in Pandas to execute this function on every comment in our Pandas Series ['comment text'], where all our comments are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train['comment_text'].apply(preprocess)\n",
    "holdout['comment_text'] = holdout['comment_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if changes are successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's compare, to see the effect the changes had"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Number to select comment\n",
    "# Has to be done before comment selection because we need to get the same comment from each dataframe \n",
    "random_number = random.randint(0,len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "CEDEM is the Electoral Commission...? And is \"\"1\"\" the best as in school grades, or is \"\"5\"\" the best?  \"\n"
     ]
    }
   ],
   "source": [
    "print(original_df['comment_text'].loc[random_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cedem is the electoral commission and is 1 the best as in school grades or is 5 the best  \n"
     ]
    }
   ],
   "source": [
    "print(train['comment_text'].loc[random_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One other pre-processing step I would like to try is to change contractions to their expanded words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dictionary of Contractions and Replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"can not\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"i'd\": \"i would\", \"i'll\": \"i will\", \"i'm\": \"i am\", \"i've\": \"i have\", \"i'd\": \"i would\", \"i'll\": \"i will\", \"i'm\": \"i am\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'll\": \"it will\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"might've\": \"might have\",\"mightn't\": \"might not\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"needn't\": \"need not\", \"shan't\": \"shall not\", \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"so've\": \"so have\",\"that'd\": \"that would\", \"that's\": \"that is\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\"they'll\": \"they will\", \"they're\": \"they are\", \"they've\": \"they have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'll\": \"we will\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"y'all\": \"you all\",\"you'd\": \"you would\", \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use string.replace to substitute each contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for replacee, replacer in contraction_dict.items():\n",
    "    train['comment_text'] = train['comment_text'].map(lambda x: x.replace(replacee, replacer))\n",
    "    holdout['comment_text'] = holdout['comment_text'].map(lambda x: x.replace(replacee, replacer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we will compare with the original again, to see if our code worked in replacing contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_number = random.randint(0,len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're correct, I missed this: Note: There is no requirement for the reverts to be related: any four reverts on the same page count. I cannot argue with the block.\n"
     ]
    }
   ],
   "source": [
    "print(original_df['comment_text'].loc[random_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are correct i missed this note there is no requirement for the reverts to be related any four reverts on the same page count i cannot argue with the block\n"
     ]
    }
   ],
   "source": [
    "print(train['comment_text'].loc[random_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since numbers are generally not used to express toxicity, they will just be taking up space.  So let's get rid of them now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train['comment_text'].map(lambda x: ''.join([i for i in x if not i.isdigit()]))\n",
    "holdout['comment_text'] = holdout['comment_text'].map(lambda x: ''.join([i for i in x if not i.isdigit()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I had to do the tokenization step on my own instead of leaving it to the SKLearn TfidfVectorizer function because I want to stem the words in our comments.  And it is easier and faster to have the text already in token form when executing the stem function\n",
    "\n",
    "- Again, I will use TweetTokenizer() for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "tokens_train = [tknzr.tokenize(x) for x in train['comment_text']]\n",
    "tokens_test = [tknzr.tokenize(x) for x in holdout['comment_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stemming takes variations of the same word and makes them all the same word\n",
    "\n",
    "- The PorterStemmer is a popular type of stemmer but there are other types.  I also tried the SnowballStemmer also from sklearn but the Porter Stemmer performed slightly better\n",
    "\n",
    "- Before I decided to use stemming, I tried out lemmatization on this data.  But it is a more complicated process than stemming so the runtimes were too long to be acceptable. I used the NLP library called Spacy during these attempts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "stemmed_tokens_train = [[porter.stem(token) for token in tokens] for tokens in tokens_train]\n",
    "stemmed_tokens_test = [[porter.stem(token) for token in tokens] for tokens in tokens_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn list of tokens back into a string, for each comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TfidfVectorizer will want the comments as strings and not a list of tokens so we must do an operation to make strings out of each list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems_for_tfidf_train = list(map(' '.join, stemmed_tokens_train))\n",
    "stems_for_tfidf_test = list(map(' '.join, stemmed_tokens_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare X and Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's finish our preparations for modeling before moving on, by defining our X and Y variables.  \n",
    "- These will be going directly into whatever models we create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, drop added columns\n",
    "train.drop(\"char_total\", axis=1, inplace=True)\n",
    "train.drop(\"total\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = stems_for_tfidf_train\n",
    "y_train = train.iloc[:,2:]\n",
    "\n",
    "X_test = stems_for_tfidf_test\n",
    "y_test = holdout.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf Vectorization Best Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I have already tuned the parameters for this process (using GridSearchCV) and found that the following yielded the best results:\n",
    "\n",
    "- sublinear_tf = True \n",
    "- max_features = 50,000\n",
    "- strip_accents = 'ascii'\n",
    "- analyzer = 'word'\n",
    "- stop_words = None\n",
    "- ngram_range = (1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a multi-label classification problem.  \n",
    "- The task is to create a prediction for each label, for each comment. \n",
    "- Each label is binary rather than multi-class.  For example, the prediction to whether a comment is a threat is always 1 or 0, yes or no.\n",
    "\n",
    "- This task calls for scoring using ROC_AUC (Receiver Operating Curve - Area Under Curve).  This is a good evaluator because it tells us how well the model can identify a positive as a positive, but also when a negative is a negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the implementation of the baseline model, I will manually run a classifier for each label.  \n",
    "- There are other ways to do this using sklearn but this way it is easy to see what is going on, and the scores for each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (Prepare Data For Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the vectorizer\n",
    "word_vectorizer = TfidfVectorizer(strip_accents='ascii', sublinear_tf=True, max_features=50000)\n",
    "\n",
    "# fit and transform on it the training features\n",
    "word_vectorizer.fit(X_train)\n",
    "X_train_word_features = word_vectorizer.transform(X_train)\n",
    "\n",
    "#transform the test features to sparse matrix\n",
    "test_features = word_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Classifiers, Output Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our evaluator, the auc roc score, deals with probabilities so we need to use the predict_proba function instead of the predict function\n",
    "\n",
    "- This code below will output the auc_roc score for each label, and then the mean of all the scores to tell us our overall score for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC score for the toxic label is 0.961616292227514\n",
      "\n",
      "ROC_AUC score for the severe_toxic label is 0.9824199471609563\n",
      "\n",
      "ROC_AUC score for the obscene label is 0.9756028080025071\n",
      "\n",
      "ROC_AUC score for the threat label is 0.9897933731935957\n",
      "\n",
      "ROC_AUC score for the insult label is 0.9682701933860691\n",
      "\n",
      "ROC_AUC score for the identity_hate label is 0.9802074538501074\n",
      "\n",
      "\u001b[1mTotal average ROC_AUC score is 0.9763183446367917\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "label_names = ['toxic','severe_toxic','obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "auc = []\n",
    "\n",
    "for label_name in label_names:\n",
    "    \n",
    "    #call the labels one column at a time so we can run the classifier on them\n",
    "    train_target = y_train[label_name]\n",
    "    test_target = y_test[label_name]\n",
    "    classifier = LogisticRegression(solver='liblinear')\n",
    "\n",
    "    \n",
    "    classifier.fit(X_train_word_features, train_target)\n",
    "    y_pred_prob = classifier.predict_proba(test_features)[:,1]\n",
    "    auc_score = metrics.roc_auc_score(test_target, y_pred_prob)\n",
    "    auc.append(auc_score)\n",
    "    print(\"ROC_AUC score for the {} label is {}\\n\".format(label_name,auc_score))\n",
    "    \n",
    "print(('\\033[1m' + 'Total average ROC_AUC score is {}' + '\\033[0m').format(np.mean(auc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Briefly visit Class Imbalances (in test set) before moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before we move on with modeling, I think it is good to remember how imbalanced the data for each label is, as this naturally will affect each score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the class imbalance for the toxic label is:\n",
      "\n",
      " [0.9048110287911469, 0.09518897120885304]\n",
      "\n",
      "\n",
      "the class imbalance for the severe_toxic label is:\n",
      "\n",
      " [0.9942636531307637, 0.0057363468692363]\n",
      "\n",
      "\n",
      "the class imbalance for the obscene label is:\n",
      "\n",
      " [0.9423082934758823, 0.05769170652411767]\n",
      "\n",
      "\n",
      "the class imbalance for the threat label is:\n",
      "\n",
      " [0.9967019913095126, 0.003298008690487355]\n",
      "\n",
      "\n",
      "the class imbalance for the insult label is:\n",
      "\n",
      " [0.9464347119322267, 0.053565288067773296]\n",
      "\n",
      "\n",
      "the class imbalance for the identity_hate label is:\n",
      "\n",
      " [0.9888711744662227, 0.011128825533777236]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in y_test.columns:\n",
    "    imb = y_test[label].value_counts(normalize=True)\n",
    "    print(\"the class imbalance for the {} label is:\\n\\n {}\\n\\n\".format(label,list(imb)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the toxic label, we see that for the test set approx 90% of the comments are labeled toxic while the other 10% were not.  So even by random chance we would still expect a 90% success rate if we guessed every comment was non-toxic.  Therefore we will hope to see our evaluation scores higher than the class imbalance ratio\n",
    "\n",
    "- Looking at our results of the baseline mode, the severe_toxic, threat, and identity_hate labels all performed worse than random guessing.  This is obviously something we will be looking to improve upon as we tune the parameters of our Logistic Regression model\n",
    "\n",
    "#### Okay, now back to modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - w/ Parameters Tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instead of manually running a classifier on each label individually like we did for the baseline model, sklearn offers built-in classes that do multi-label classification automatically.\n",
    "\n",
    "- I was able to find 2 options for this, OneVsRestClassifier and MultiOutputClassifier.  The OneVsRestClassifier is built to handle multi-class classification but the docs suggest that it also works for multi-label classification:\n",
    "\n",
    "\"This strategy can also be used for multilabel learning, where a classifier is used to predict multiple labels for instance, by fitting on a 2-d matrix in which cell [i, j] is 1 if sample i has label j and 0 otherwise.\"\n",
    "\n",
    "- The OneVsRestClassifier seemed a little faster than the MultiOutPutClassifier so I used this method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- solver = 'sag'\n",
    "- C = 2\n",
    "- class_weight = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    TfidfVectorizer(sublinear_tf=1, max_features=50000, strip_accents='ascii'),\n",
    "    OneVsRestClassifier(LogisticRegression(solver='sag', C=2))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Score (w/ Cross Validation) for Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815438159242728"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = np.mean(cross_val_score(pipe_lr, X_train, y_train, cv=3, scoring='roc_auc'))\n",
    "train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Score (w/ Cross Validation) for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765287876495451"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.fit(X_train, y_train)\n",
    "test_preds = pipe_lr.predict_proba(X_test)\n",
    "test_score = metrics.roc_auc_score(y_test, test_preds)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts on Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I see 2 main things for these results:\n",
    "    - Our score only increased by .0002 with the best performing parameters.  That is disappointing\n",
    "    - There seems to be some slight overfitting, as the difference between the train score and test score is .4%\n",
    "\n",
    "- Nevertheless, this is the best results a logistic regression model could do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The other machine learning model I would like to try is the Random Forest\n",
    "- We will do it the same way we did with Logistic Regression\n",
    "- Here we go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC score for the toxic label is 0.9327543346259035\n",
      "\n",
      "ROC_AUC score for the severe_toxic label is 0.8433429482853397\n",
      "\n",
      "ROC_AUC score for the obscene label is 0.9402384310751769\n",
      "\n",
      "ROC_AUC score for the threat label is 0.7730231514510358\n",
      "\n",
      "ROC_AUC score for the insult label is 0.9225250879992609\n",
      "\n",
      "ROC_AUC score for the identity_hate label is 0.8345308661094569\n",
      "\n",
      "\u001b[1mTotal average ROC_AUC score is 0.8744024699243623\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "label_names = ['toxic','severe_toxic','obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "auc = []\n",
    "\n",
    "for label_name in label_names:\n",
    "    \n",
    "    #call the labels one column at a time so we can run the classifier on them\n",
    "    train_target = y_train[label_name]\n",
    "    test_target = y_test[label_name]\n",
    "    classifier = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "    \n",
    "    classifier.fit(X_train_word_features, train_target)\n",
    "    y_pred_prob = classifier.predict_proba(test_features)[:,1]\n",
    "    auc_score = metrics.roc_auc_score(test_target, y_pred_prob)\n",
    "    auc.append(auc_score)\n",
    "    print(\"ROC_AUC score for the {} label is {}\\n\".format(label_name,auc_score))\n",
    "    \n",
    "print(('\\033[1m' + 'Total average ROC_AUC score is {}' + '\\033[0m').format(np.mean(auc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wow, the baseline Random Forest model did terrible.  Let's see if parameter tuning will change that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest w/ Parameters Tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best peforming parameters using GridSearch are:\n",
    "\n",
    "- min_samples_split = 8\n",
    "- min_samples_leaf = 6\n",
    "- criterion = 'entropy'\n",
    "- max_depth = None\n",
    "- class_weight = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = make_pipeline(\n",
    "    TfidfVectorizer(sublinear_tf=True, max_features=50000, strip_accents='ascii'),\n",
    "    OneVsRestClassifier(RandomForestClassifier(min_samples_leaf=6, min_samples_split=8, criterion='entropy'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Score (w/ Cross Validation) for Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9738634646305023"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score = np.mean(cross_val_score(pipe_rf, X_train, y_train, cv=3, scoring='roc_auc'))\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Score (w/ Cross Validation) for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9719592771338132"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf.fit(X_train, y_train)\n",
    "test_preds = pipe_rf.predict_proba(X_test)\n",
    "metrics.roc_auc_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts on Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Huge improvement from the baseline model\n",
    "\n",
    "- But still not as good as our logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model (from start to finish)\n",
    "## No preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, while I was doing testing, making small changes in all phases of the process trying to get the best score possible, I realized that the models actually did better without all the preprocessing steps.  \n",
    "\n",
    "- That was disappointing since a lot of work went into coming up with those steps but it is interesting and notable nonetheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "holdout = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_df = pd.read_csv(\"test_labels.csv\")\n",
    "holdout = holdout.merge(test_labels_df, on='id')\n",
    "holdout.drop(holdout[holdout['toxic']==-1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "tokens = [tknzr.tokenize(x) for x in train['comment_text']]\n",
    "tokens_test = [tknzr.tokenize(x) for x in holdout['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "list_of_stems_lists = [[porter.stem(token) for token in tokens] for tokens in tokens]\n",
    "test_list_of_stems_lists = [[porter.stem(token) for token in tokens] for tokens in tokens_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems_for_tfidf = list(map(' '.join, list_of_stems_lists))\n",
    "test_stems_for_tfidf = list(map(' '.join, test_list_of_stems_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = stems_for_tfidf\n",
    "y_train = train.iloc[:,2:]\n",
    "\n",
    "X_test = test_stems_for_tfidf\n",
    "y_test = holdout.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    TfidfVectorizer(sublinear_tf=1, max_features=45000, strip_accents='ascii'),\n",
    "    OneVsRestClassifier(LogisticRegression(solver='sag', C=1.85))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822050892061615"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score = np.mean(cross_val_score(pipe_lr, X_train, y_train, cv=3, scoring='roc_auc'))\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9780044814452508"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.fit(X_train, y_train)\n",
    "test_preds = pipe_lr.predict_proba(X_test)\n",
    "metrics.roc_auc_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So we see an improvement from 97.65% to 97.80% by removing all of the preprocessing steps.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best Model\n",
    "    - no preprocessing\n",
    "    - TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "    - TfidfVectorizer(sublinear_tf=True, max_features=50000, strip_accents='ascii')\n",
    "    - LogisticRegression(solver='sag', C=2)\n",
    "    \n",
    "- Best Score\n",
    "    - Train: .9822\n",
    "    - Test: .9780\n",
    "    \n",
    "- Kaggle Score\n",
    "    - My Private Score: .97833 (rank 2745/4550)\n",
    "    - My Public Score: .97714\n",
    "    - Top Private Score: .98856\n",
    "    - Top Public Score: .98901\n",
    "\n",
    "- Deep Learning Attempt (See Deep Learning Notebook)\n",
    "    - Train Accuracy Score: .9829\n",
    "    - Validation Accuracy Score: .9822"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, I think this project was a success.  My best model was able to classify comments for 6 different sub-classes of toxicity at an average of 97.83% accuracy.  And this is on unseen data!  Our model can recognize what makes a comment toxic and apply that to comments with potentially totally different groups of words than our training set.  That is impressive and useful because the goal is to classify new comments being made all the time.  As long as the internet exists, there will be communication between people on the internet in text form.  \n",
    "\n",
    "Due to our model's success in classification ability, I think our shareholders would be happy.  Our model is not perfect and there are better models out there, but our model runs fast and doesn't take up a lot of resources while still being extremely accurate.  I think the model could be used exactly as it stands now, to help clean up the comments of any website that has a forum of user to user communication.  These are the places where, unfortunately, toxic language and cruelty sometimes exist.  This model can help automatically remove those comments with great speed, so users with good intentions are not subject to unjustified hate and toxicity.  The internet would be a better and more productive place overall with the use of my model and others like it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
